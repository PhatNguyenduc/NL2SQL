# ğŸ”„ NL2SQL - Natural Language to SQL Converter

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)

ğŸš€ **High-Performance Backend API** chuyá»ƒn Ä‘á»•i cÃ¢u há»i tiáº¿ng tá»± nhiÃªn thÃ nh SQL queries vá»›i kiáº¿n trÃºc tá»‘i Æ°u, multi-layer caching, vÃ  há»— trá»£ Ä‘a LLM providers.

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         NL2SQL System                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  React   â”‚â”€â”€â”€â–¶â”‚ FastAPI  â”‚â”€â”€â”€â–¶â”‚  Redis   â”‚â”€â”€â”€â–¶â”‚  MySQL   â”‚  â”‚
â”‚  â”‚ Frontend â”‚    â”‚ Backend  â”‚    â”‚  Cache   â”‚    â”‚ Database â”‚  â”‚
â”‚  â”‚  :3000   â”‚â—€â”€â”€â”€â”‚  :8000   â”‚â—€â”€â”€â”€â”‚  :6379   â”‚â—€â”€â”€â”€â”‚  :3307   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                        â”‚                                         â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚         â–¼              â–¼              â–¼                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚  Semantic  â”‚ â”‚Query Plan  â”‚ â”‚  General   â”‚                  â”‚
â”‚  â”‚   Cache    â”‚ â”‚   Cache    â”‚ â”‚   Cache    â”‚                  â”‚
â”‚  â”‚(Embedding) â”‚ â”‚ (Pattern)  â”‚ â”‚  (Redis)   â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                        â”‚                                         â”‚
â”‚                        â–¼                                         â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚        â”‚      Multi-LLM Providers        â”‚                      â”‚
â”‚        â”‚  Gemini â”‚ OpenAI â”‚ Claude â”‚ ... â”‚                      â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> ğŸ“š **Chi tiáº¿t kiáº¿n trÃºc**: [docs/architecture.md](docs/architecture.md)

---

## âœ¨ TÃ­nh nÄƒng ná»•i báº­t

### ğŸš€ Performance Optimizations

- **3-Layer Caching**: Semantic Cache + Query Plan Cache + Redis
- **Async LLM Calls**: Non-blocking I/O, 4x throughput improvement
- **Connection Pooling**: Optimized database connections
- **Schema Optimization**: 60-70% token reduction

### ğŸ¤– Intelligent SQL Generation

- **Multi-LLM Provider**: OpenAI, Gemini (FREE), OpenRouter, Claude, Azure
- **Auto-Fallback**: Tá»± Ä‘á»™ng chuyá»ƒn provider khi cáº§n
- **SQL Execution Feedback**: Tá»± Ä‘á»™ng retry vá»›i error context
- **Query Type Classification**: Optimize prompt per query type

### ğŸ“Š Monitoring & Analytics

- **Real-time Dashboard**: Query stats, cache performance, error analysis
- **Hourly Trends**: Visualize usage patterns
- **Confidence Tracking**: Monitor SQL generation quality

### ğŸ›¡ï¸ Security & Reliability

- **Read-only Enforcement**: Chá»‰ SELECT queries
- **SQL Injection Prevention**: Multi-layer validation
- **Graceful Degradation**: Auto-recovery mechanisms

---

## âš¡ Performance Highlights

| Feature            | Improvement    | How                          |
| ------------------ | -------------- | ---------------------------- |
| **Cache Hit**      | ~50ms response | Semantic similarity matching |
| **Token Usage**    | -60-70%        | Schema optimization          |
| **Throughput**     | 4x             | Async LLM calls              |
| **Error Recovery** | Auto-fix       | SQL execution feedback       |

### Caching Strategy

```
Question: "How many users?"
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 1: SEMANTIC CACHE                                      â”‚
â”‚ "Count all users" â‰ˆ "How many users?" (similarity: 0.95)    â”‚
â”‚ â†’ Return cached SQL instantly (~50ms)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 2: QUERY PLAN CACHE                                    â”‚
â”‚ "Top 5 users" â†’ TOP_N pattern template                      â”‚
â”‚ "Top 10 products" â†’ Same template, different params         â”‚
â”‚ â†’ Fill template without LLM call                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 3: GENERAL CACHE (Redis)                               â”‚
â”‚ Schema, prompts, execution results                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Technical Stack

| Component           | Technology                     | Purpose                        |
| ------------------- | ------------------------------ | ------------------------------ |
| **API Framework**   | FastAPI + Uvicorn              | High-performance async API     |
| **LLM Integration** | Instructor + httpx             | Structured output, async calls |
| **Database**        | MySQL 8.0 + SQLAlchemy         | Connection pooling, ORM        |
| **Caching**         | Redis 7 + In-memory            | Multi-layer caching            |
| **Embeddings**      | OpenAI / Sentence-Transformers | Semantic similarity            |
| **Frontend**        | React 18 + TypeScript + Vite   | Modern SPA with dark theme      |
| **UI Framework**   | Tailwind CSS + Custom CSS      | Responsive design, animations  |
| **Container**       | Docker Compose                 | Full stack deployment          |

---

## ğŸš€ Quick Start (5 phÃºt)

### 1ï¸âƒ£ Clone & Setup

```powershell
# Clone repository
git clone https://github.com/PhatNguyenduc/NL2SQL.git
cd NL2SQL

# Copy vÃ  config .env
copy .env.example .env
# Chá»‰nh sá»­a .env vá»›i API keys (xem bÆ°á»›c 2)
```

### 2ï¸âƒ£ Chá»n LLM Provider

**Option A: Gemini (FREE - Recommended)** ğŸ

```bash
# .env
LLM_PROVIDER=gemini
GEMINI_API_KEY=your-key-here  # FREE táº¡i: https://aistudio.google.com/apikey
```

**Option B: OpenAI**

```bash
# .env
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-your-key-here
```

**Option C: OpenRouter** (100+ models)

```bash
# .env
LLM_PROVIDER=openrouter
OPENROUTER_API_KEY=sk-or-your-key-here  # https://openrouter.ai/keys
```

> ğŸ“š **Chi tiáº¿t providers**: Xem [docs/llm_providers.md](docs/llm_providers.md)

### 3ï¸âƒ£ Cháº¡y Full Stack vá»›i Docker

```bash
# Quick start (Linux/macOS)
./start.sh

# Quick start (Windows)
.\start.ps1

# Hoáº·c manual
docker-compose up -d --build
```

**âœ… Script sáº½:**
- Kiá»ƒm tra Docker
- Validate API keys (auto fallback náº¿u cáº§n)
- Start MySQL (port 3307), Redis (port 6379), API (port 8000), Frontend (port 3000)
- Import schema + Generate sample data (500 users, 1000 products, 2000 orders)
- Test health checks

**Services Ready:**

- ğŸ¨ **React Frontend**: http://localhost:3000
- ğŸ”— **API**: http://localhost:8000
- ğŸ“– **API Docs**: http://localhost:8000/docs
- ğŸ—„ï¸ **phpMyAdmin**: http://localhost:8080 (optional, use `--profile tools`)
- ğŸ’¾ **MySQL**: localhost:3307 (root/admin)
- ğŸ’¾ **Redis**: localhost:6379

### 4ï¸âƒ£ Test API

**Option A: Use React UI** (Recommended)

Frontend React Ä‘Ã£ cháº¡y tá»± Ä‘á»™ng vá»›i Docker Compose táº¡i **http://localhost:3000**

**Hoáº·c cháº¡y local development:**

```bash
cd frontend
npm install
npm run dev
# App sáº½ cháº¡y táº¡i http://localhost:3000
```

**Option B: Use cURL**

```powershell
# Health check
curl http://localhost:8000/health

# Chat vá»›i database (generate + execute)
curl -X POST http://localhost:8000/chat `
  -H "Content-Type: application/json" `
  -d '{
    "message": "How many users do we have?",
    "execute_query": true
  }'

# Xem schema
curl http://localhost:8000/schema
```

**Response example:**

```json
{
  "session_id": "abc123",
  "sql_generation": {
    "query": "SELECT COUNT(*) AS user_count FROM users;",
    "confidence": 0.95,
    "explanation": "Counts total users in database"
  },
  "execution": {
    "success": true,
    "rows": [{ "user_count": 500 }],
    "row_count": 1
  }
}
```

---

## ğŸ“š API Endpoints

### ğŸ”¹ Chat - Generate & Execute SQL

```http
POST /chat
```

**Request:**

```json
{
  "message": "Show me top 10 products by sales",
  "execute_query": true,
  "session_id": "optional-session-id",
  "temperature": 0.1
}
```

**Response:**

```json
{
  "session_id": "abc123",
  "sql_generation": {
    "query": "SELECT p.product_name, SUM(oi.quantity) as total_sales\nFROM products p\nJOIN order_items oi ON p.product_id = oi.product_id\nGROUP BY p.product_id, p.product_name\nORDER BY total_sales DESC\nLIMIT 10;",
    "confidence": 0.92,
    "explanation": "Joins products with order_items, aggregates sales, returns top 10"
  },
  "execution": {
    "success": true,
    "rows": [
      { "product_name": "iPhone 14", "total_sales": 245 },
      { "product_name": "MacBook Pro", "total_sales": 189 }
    ],
    "row_count": 10,
    "execution_time": 0.023
  }
}
```

### ğŸ”¹ Batch Processing

```http
POST /chat/batch
```

**Request:**

```json
{
  "messages": [
    "How many users?",
    "Show top 5 categories",
    "Average order value"
  ],
  "execute_queries": true,
  "session_id": "batch-session"
}
```

### ğŸ”¹ Schema Info

```http
GET /schema
```

Returns database structure (24 tables: users, products, orders, etc.)

### ğŸ”¹ Conversation History

```http
POST /conversation/history
```

```json
{
  "session_id": "abc123",
  "limit": 50
}
```

### ğŸ”¹ Health Check

```http
GET /health
```

**Response:**

```json
{
  "status": "healthy",
  "database_connected": true,
  "llm_provider": "gemini",
  "llm_model": "gemini-1.5-flash",
  "tables": 24
}
```

> ğŸ“– **Full API Docs**: http://localhost:8000/docs (Swagger UI)

---

## ğŸ¯ VÃ­ dá»¥ Queries

### Aggregations

```
"How many users do we have?"
"What's the average order value?"
"Total revenue this month"
```

### Filtering

```
"Show users registered after 2024-01-01"
"Products with price above $100"
"Orders with status 'delivered'"
```

### Joins

```
"Show orders with customer names"
"Products with their categories"
"Users with their order history"
```

### Sorting & Limiting

```
"Top 10 customers by spending"
"Latest 20 orders"
"5 most expensive products"
```

### Grouping

```
"Revenue by month"
"Order count by status"
"Average rating per product category"
```

---

## ğŸ”§ Cáº¥u hÃ¬nh

### Environment Variables (.env)

```bash
# ============================================
# LLM Provider Configuration
# ============================================
LLM_PROVIDER=gemini              # openai | gemini | openrouter | anthropic | azure_openai

# Gemini (FREE)
GEMINI_API_KEY=your-key-here
GEMINI_MODEL=gemini-1.5-flash

# OpenAI
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4o-mini

# OpenRouter
OPENROUTER_API_KEY=sk-or-your-key-here
OPENROUTER_MODEL=openai/gpt-4o-mini

# Anthropic Claude
ANTHROPIC_API_KEY=sk-ant-your-key-here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Azure OpenAI
AZURE_OPENAI_API_KEY=your-key-here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
AZURE_OPENAI_DEPLOYMENT=your-deployment
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# Advanced LLM Settings
LLM_TEMPERATURE=0.1
LLM_MAX_RETRIES=3
LLM_TIMEOUT=30

# ============================================
# Database Configuration
# ============================================
DATABASE_URL=mysql+pymysql://root:admin@mysql:3306/ecommerce

# ============================================
# Server Configuration
# ============================================
HOST=0.0.0.0
PORT=8000
DEFAULT_LIMIT=100
LOG_LEVEL=INFO
CORS_ORIGINS=*
```

---

## ğŸ³ Docker Commands

```bash
# Quick start (recommended)
./start.sh          # Linux/macOS
.\start.ps1         # Windows

# Hoáº·c manual commands:
docker-compose -f docker-compose.full.yml up -d --build
docker-compose -f docker-compose.full.yml logs -f
docker-compose -f docker-compose.full.yml down

# Restart services
docker-compose -f docker-compose.full.yml restart

# Restart chá»‰ API (sau khi Ä‘á»•i LLM provider)
docker-compose -f docker-compose.full.yml restart nl2sql-api

# MySQL CLI
docker exec -it nl2sql-mysql mysql -u root -padmin ecommerce
```

---

## ğŸ’» Local Development (khÃ´ng dÃ¹ng Docker)

```powershell
# 1. CÃ i Ä‘áº·t dependencies
python -m venv venv
.\venv\Scripts\Activate.ps1
pip install -r requirements.txt

# 2. Setup MySQL (riÃªng biá»‡t)
# - CÃ i MySQL 8.0
# - Import resources/data/ecommerce_schema.sql
# - Run resources/data/generate_data.py

# 3. Config .env
DATABASE_URL=mysql+pymysql://root:admin@localhost:3307/ecommerce
LLM_PROVIDER=gemini
GEMINI_API_KEY=your-key-here

# 4. Run API server
python main.py

# Server cháº¡y táº¡i: http://localhost:8000
```

---

## ğŸ“Š Database Schema

**24 Tables** trong `ecommerce` database:

### Core Tables

- `users` - User accounts (500 records)
- `products` - Products catalog (1000 records)
- `categories` - Product categories (30 records)
- `brands` - Product brands (50 records)

### Orders

- `orders` - Order headers (2000 records)
- `order_items` - Order line items
- `order_addresses` - Shipping/billing addresses
- `order_status_history` - Status changes
- `transactions` - Payment transactions
- `shipments` - Shipping info

### Product Management

- `product_variants` - Product variations (size, color)
- `product_images` - Product images
- `product_attributes` - Custom attributes
- `variant_attributes` - Variant-specific attributes
- `product_categories` - Many-to-many relation
- `inventory` - Stock levels

### Customer Features

- `user_addresses` - Saved addresses
- `shopping_carts` - Active carts
- `cart_items` - Cart contents
- `product_reviews` - Reviews & ratings
- `wishlists` - Wishlist items

### Marketing

- `coupons` - Discount coupons
- `coupon_usage` - Coupon redemptions

### Configuration

- `payment_methods` - Payment options
- `shipping_methods` - Shipping options

> ğŸ“„ **Full schema**: `resources/data/ecommerce_schema.sql`

---

## ğŸ¤– Multi-LLM Provider Support

### Supported Providers

| Provider         | Free Tier       | Cost     | Best For                 |
| ---------------- | --------------- | -------- | ------------------------ |
| **Gemini**       | âœ… 1500 req/day | FREE     | Development, learning    |
| **OpenRouter**   | âœ… Some models  | $ - $$$  | Access to 100+ models    |
| **OpenAI**       | $5 credit       | $$$      | Production, best quality |
| **Claude**       | $5 credit       | $$ - $$$ | Complex reasoning        |
| **Azure OpenAI** | âŒ None         | $$$      | Enterprise, compliance   |

### Auto Fallback Logic

```
1. Äá»c LLM_PROVIDER tá»« .env
2. Náº¿u khÃ´ng set hoáº·c key invalid:
   â†’ Try Gemini (FREE)
   â†’ Try OpenAI
   â†’ Try OpenRouter
   â†’ Error náº¿u khÃ´ng cÃ³ key nÃ o
3. Validate API key format
4. Initialize client
```

### Switching Providers

```powershell
# Chá»‰nh .env
LLM_PROVIDER=gemini

# Restart API
docker-compose -f docker-compose.full.yml restart nl2sql-api

# Hoáº·c local:
python main.py
```

> ğŸ“š **Provider details**: [docs/llm_providers.md](docs/llm_providers.md)

---

## ğŸ›¡ï¸ Security & Safety

### âœ… Implemented

- **Read-only**: Chá»‰ cho phÃ©p `SELECT` queries
- **Query validation**: Block INSERT, UPDATE, DELETE, DROP, ALTER, TRUNCATE, etc.
- **SQL injection prevention**: Parameterized queries
- **Auto LIMIT**: ThÃªm LIMIT tá»± Ä‘á»™ng náº¿u thiáº¿u
- **Input validation**: Pydantic models cho má»i input
- **Error handling**: Graceful error messages, khÃ´ng expose internals

### âš ï¸ Production Recommendations

- **Authentication**: ThÃªm API keys hoáº·c JWT
- **Rate limiting**: Giá»›i háº¡n requests/IP
- **HTTPS**: Sá»­ dá»¥ng reverse proxy (Nginx/Traefik)
- **Monitoring**: Setup logging vÃ  alerts
- **Backup**: Regular database backups

---

## ğŸ“ Project Structure

```
NL2SQL/
â”œâ”€â”€ main.py                          # FastAPI entry point + Analytics
â”œâ”€â”€ docker-compose.yml               # Full stack Docker config
â”œâ”€â”€ Dockerfile                       # API container image
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ models.py               # API request/response models (Pydantic)
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ chat_service.py         # Chat logic + SQL Execution Feedback
â”‚   â”‚   â””â”€â”€ async_chat_service.py   # Async version for high throughput
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                        # ğŸ”§ CORE COMPONENTS
â”‚   â”‚   â”œâ”€â”€ converter.py            # Main NL2SQL converter pipeline
â”‚   â”‚   â”œâ”€â”€ async_converter.py      # Async version (4x throughput)
â”‚   â”‚   â”œâ”€â”€ llm_provider.py         # Multi-LLM adapter (5 providers)
â”‚   â”‚   â”œâ”€â”€ schema_extractor.py     # DB schema analysis
â”‚   â”‚   â”œâ”€â”€ schema_optimizer.py     # Token reduction (60-70%)
â”‚   â”‚   â”œâ”€â”€ query_executor.py       # Safe SQL execution
â”‚   â”‚   â”œâ”€â”€ query_preprocessor.py   # Query classification
â”‚   â”‚   â”œâ”€â”€ sql_validator.py        # SQL validation + post-processing
â”‚   â”‚   â”œâ”€â”€ prompt_builder.py       # Optimized prompt construction
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ cache_manager.py        # General Redis cache
â”‚   â”‚   â”œâ”€â”€ semantic_cache.py       # Embedding-based cache (Layer 1)
â”‚   â”‚   â”œâ”€â”€ query_plan_cache.py     # Pattern-based cache (Layer 2)
â”‚   â”‚   â”œâ”€â”€ embedding_provider.py   # Embedding generation
â”‚   â”‚   â””â”€â”€ schema_version_manager.py # Cache invalidation
â”‚   â”‚
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ system_prompt.py        # LLM system prompts
â”‚   â”‚   â””â”€â”€ few_shot_examples.py    # Example queries
â”‚   â”‚
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ sql_query.py            # Core data models
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ home.tsx                # Main chat UI component
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â””â”€â”€ Analytics.tsx       # Analytics dashboard
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â””â”€â”€ client.ts           # API client & types
â”‚   â”‚   â”œâ”€â”€ main.tsx                # App entry point
â”‚   â”‚   â””â”€â”€ index.css               # Styles & animations
â”‚   â”œâ”€â”€ Dockerfile                  # Frontend container (Nginx)
â”‚   â”œâ”€â”€ package.json                # Node dependencies
â”‚   â””â”€â”€ vite.config.ts              # Build configuration
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md             # ğŸ—ï¸ Technical deep-dive
â”‚   â””â”€â”€ llm_providers.md            # LLM provider guide
â”‚
â””â”€â”€ resources/
    â””â”€â”€ data/
        â”œâ”€â”€ ecommerce_schema.sql    # MySQL schema (24 tables)
        â””â”€â”€ seed.py                 # Sample data generator
```

---

## ğŸ”¬ Key Technical Decisions

### 1. Why Multi-Layer Caching?

```
Problem: LLM calls are expensive ($) and slow (2-10s)
Solution: 3-layer cache hierarchy

Layer 1 - Semantic Cache:
  "How many users?" â‰ˆ "Count all users"
  â†’ Same meaning, different words
  â†’ Use embeddings to find similar questions
  â†’ Return cached SQL (saves LLM call)

Layer 2 - Query Plan Cache:
  "Top 5 users by orders" â†’ TOP_N pattern
  "Top 10 products by sales" â†’ Same pattern!
  â†’ Extract pattern, fill template
  â†’ No LLM needed for common patterns

Layer 3 - General Cache:
  â†’ Schema, prompts, results in Redis
  â†’ Fast key-value lookup
```

### 2. Why Instructor for LLM?

```python
# Without Instructor (error-prone):
response = client.chat.completions.create(...)
try:
    data = json.loads(response.content)
    sql = data.get("query", "")  # Might fail!
except: ...

# With Instructor (guaranteed structure):
response = client.chat.completions.create(
    response_model=SQLQuery,  # Pydantic model
    ...
)
# response.query, response.confidence always exist!
```

### 3. Why SQL Execution Feedback?

```
Problem: LLM generates valid-looking SQL but fails on execution

Example:
  Input: "Top 5 users this month AND last month"
  LLM Output: SELECT ... ORDER BY x LIMIT 5 UNION ALL SELECT ...
  MySQL Error: Syntax error near 'UNION'

Solution - Feedback Loop:
  1. Execute SQL
  2. If error â†’ Send error message back to LLM
  3. LLM corrects: (SELECT ... LIMIT 5) UNION ALL (SELECT ... LIMIT 5)
  4. Retry (max 2 times)
```

### 4. Why Schema Optimization?

```
Problem: 24 tables Ã— 10 columns = 240 items â†’ Too many tokens

Solution:
  1. Compact format: table.column (no data types when not needed)
  2. Relevant filtering: Only include tables mentioned in question
  3. FK mapping: Help LLM understand JOINs

Result: 60-70% token reduction â†’ Faster + Cheaper
```

---

## ğŸ§ª Testing

```powershell
# Install test dependencies
pip install pytest pytest-cov

# Run all tests
pytest

# With coverage
pytest --cov=src --cov-report=html

# Specific test file
pytest tests/test_converter.py -v

# Integration tests (requires DB + API key)
$env:DATABASE_URL="mysql+pymysql://root:admin@localhost:3307/ecommerce"
$env:LLM_PROVIDER="gemini"
$env:GEMINI_API_KEY="your-key"
pytest tests/ -m integration
```

---

## ğŸ¤ Contributing

Contributions are welcome! ğŸ‰

1. Fork repository
2. Create feature branch: `git checkout -b feature/AmazingFeature`
3. Commit changes: `git commit -m 'Add AmazingFeature'`
4. Push to branch: `git push origin feature/AmazingFeature`
5. Open Pull Request

---

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

- **OpenAI** - GPT models
- **Google** - Gemini models (FREE tier!)
- **Anthropic** - Claude models
- **OpenRouter** - Multi-model access
- **FastAPI** - Modern web framework
- **instructor** - Structured LLM outputs
- **SQLAlchemy** - Database ORM

---

## ğŸ“ Support

- ğŸ“§ Email: phatnguyen@example.com
- ğŸ› Issues: [GitHub Issues](https://github.com/PhatNguyenduc/NL2SQL/issues)
- ğŸ’¬ Discussions: [GitHub Discussions](https://github.com/PhatNguyenduc/NL2SQL/discussions)

---

## ğŸ—ºï¸ Roadmap

- [x] ~~Multi-LLM Provider Support~~
- [x] ~~Multi-Layer Caching (Semantic + Query Plan)~~
- [x] ~~Analytics Dashboard~~
- [x] ~~SQL Execution Feedback Loop~~
- [x] ~~Async High-Performance Endpoints~~
- [ ] Support for PostgreSQL
- [ ] CLI interface
- [ ] Query optimization suggestions
- [ ] Multi-language support (Vietnamese NLP)
- [ ] Export to CSV/Excel
- [ ] Query templates library
- [ ] User authentication & permissions

---

## ğŸ“Š Monitoring & Analytics

Access the **Analytics Dashboard** at http://localhost:3000 (click ğŸ“Š Analytics in sidebar)

**Available Metrics:**

- Query statistics (total, success rate, errors)
- Response time distribution
- Cache hit rates (semantic vs LLM calls)
- Table usage frequency
- Confidence score distribution
- Hourly query trends
- Error type analysis

**API Endpoints:**

```http
GET /analytics/dashboard     # Full analytics data
GET /monitoring/cache/all    # All cache statistics
GET /health                  # System health check
```

---

â­ **If you find this project useful, please give it a star!**

Made with â¤ï¸ by [PhatNguyenduc](https://github.com/PhatNguyenduc)
